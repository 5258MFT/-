# -
主要用于爬取51招聘网和猎聘网的招聘数据

下载后直接使用vscode新建项目，然后加入这些文件
整个项目的主要流程是从多个招聘网站爬取招聘信息，将这些信息保存到 CSV 文件中，然后合并这些 CSV 文件，对合并后的数据进行去重处理，最后对清洗后的数据进行可视化分析。配置文件则用于管理项目的开发环境和版本控制。

1. 配置浏览器环境（1.py）
   目标：确保爬虫程序能够正确调用 Chrome 浏览器进行网页自动化操作。
   详细步骤：
   路径设置：使用 DrissionPage 库的 ChromiumOptions 类，手动指定 Chrome 浏览器的可执行文件路径（如 C:\Program Files\Google\Chrome\Application\Chrome.exe）。
   配置保存：将路径配置保存为项目默认设置，后续爬虫脚本无需重复指定，直接调用已保存的配置。
   依赖：需提前安装 DrissionPage 库（pip install DrissionPage）。
   作用：为后续爬虫脚本提供稳定的浏览器环境，避免因路径问题导致程序启动失败。

   整体技术链路
   环境层：Chrome 浏览器 + DrissionPage 自动化框架。
   数据采集层：多脚本分工爬取不同平台数据，兼顾全面性与效率。
   数据处理层：pandas 进行数据合并、清洗，保证数据质量。
   数据分析层：pyecharts 生成直观可视化图表，支持决策参考。
   优势：模块化设计使各环节可独立维护，扩展性强（如新增爬取平台只需添加对应脚本）。
